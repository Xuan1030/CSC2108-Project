import os, openai, pickle, json, base64
from tqdm import tqdm

# Set the API key
openai.api_key = os.getenv("OPENAI_API_KEY")

MODEL = "gpt-4o"
N = 5

# Universal prompts
user_prompt = f"Analyze {N} front, {N} middle, and {N} background feature words of the image given. Provide the answer in format: " + \
"'fr': 'feature_1', 'feature_2', ...; 'md': 'feature_1', 'feature_2', ...; 'bg': 'feature_1', 'feature_2', ..."


def img_to_base64(image_path: str):
    '''
    Convert image to base64 format

    @param image_path: The path to image to be converted
    @return: The base64 string
    '''
    with open(image_path, "rb") as image_file:
        base64_image = base64.b64encode(image_file.read()).decode("utf-8")
    return base64_image


def img_feature_analysis_GPT(image_path: str):
    '''
    Ask GPT to describe the front, middle, background features of image. 
    This is single API call. Running it will cost 2x

    @param image_path: The path to image to be analyzed
    @return: The features generated by GPT-4o, in 3 lists
    '''
    
    client = openai.OpenAI()

    base64_image = img_to_base64(image_path)

    response = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "user", "content": 
             [
                {"type": "text", "text": user_prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
             ]}
        ],
        max_tokens=1000
    )

    # Extract and print the assistant's reply
    return response



def create_api_request_GPT(prompts, image_path, max_tokens=1000):
    '''
    Create a json file with the prompt and image for GPT API

    @param prompts: The prompt to be sent to GPT
    @param image: The image to be sent to GPT
    @return: The json file
    '''

    base64_image = img_to_base64(image_path)
    json_request = {
        "custom_id": image_path.replace("/", "_"),
        "method": "POST",
        "url": "/v1/chat/completions",
        "body": {
            "model": MODEL,
            "messages": [
                {"role": "user", "content": [
                    {"type": "text", "text": prompts},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpg;base64,{base64_image}"}}
                ]},
            ],
            "max_tokens": max_tokens
        }
    }

    return json_request



def create_batch_api_json_GPT(img_folder, save_path):
    '''
    Create a json file with all the images in the folder for batch processing

    @param img_folderh: The path to the folder containing images
    @param save_path: The path to save the json file
    '''
    for foldername, subfolders, filenames in os.walk(img_folder):
        # Count the number of files in the current folder
        if foldername == img_folder:
            continue
        
        tasks = []
        for filename in tqdm(os.listdir(foldername)):
            if filename.lower().endswith(('.jpg')):
                task = create_api_request_GPT(user_prompt, os.path.join(foldername, filename))
                tasks.append(task)

        out_json_path = os.path.join(save_path, foldername.split("\\")[-1] + ".jsonl")
        print(f"Saving {foldername}")
        with open(out_json_path, 'w') as output_file:
            for task in tqdm(tasks):
                json.dump(task, output_file)
                output_file.write('\n')



if __name__ == "__main__":
    # res = img_feature_analysis("image.jpg")
    # pickle.dump(res, open("response.pkl", "wb"))

    # res = pickle.load(open("response.pkl", "rb"))

    # print(res.choices[0].message.content)

    # Create Batch API for GPT4
    create_batch_api_json_GPT("datasets/original_dataset", "datasets/GPT_request_batches")
